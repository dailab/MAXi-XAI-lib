<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>maxi.lib.explanation.explanation_generator API documentation</title>
<meta name="description" content="Explanation Generator" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>maxi.lib.explanation.explanation_generator</code></h1>
</header>
<section id="section-intro">
<p>Explanation Generator</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Explanation Generator&#34;&#34;&#34;

__all__ = [&#34;ExplanationGenerator&#34;]

import traceback
from collections import OrderedDict
from typing import Any, Callable, Type, Tuple, OrderedDict, Dict, Union

import numpy as np
from scipy.optimize import OptimizeResult

from ..computation_components.gradient.gradient_estimator import (
    URVGradientEstimator,
)
from ..computation_components.gradient.base_gradient import BaseGradient
from ..computation_components.optimizer.base_optimizer import (
    BaseOptimizer,
)
from ..computation_components.optimizer.ada_exp_grad import (
    AdaExpGradOptimizer,
)
from ...data.data_types import (
    MetaData,
)
from ..loss.base_explanation_model import BaseExplanationModel
from ..loss.cem_loss import CEMLoss
from ..inference.inference_wrapper import InferenceWrapper
from ...utils import logger, general


class ExplanationGenerator:
    def __init__(
        self,
        loss: Type[BaseExplanationModel] = CEMLoss,
        optimizer: Type[BaseOptimizer] = AdaExpGradOptimizer,
        gradient: Type[BaseGradient] = URVGradientEstimator,
        loss_kwargs: Dict[str, str] = {
            &#34;mode&#34;: &#34;PP&#34;,
            &#34;c&#34;: 100,
            &#34;gamma&#34;: 0,
            &#34;K&#34;: 50,
            &#34;AE&#34;: None,
        },
        optimizer_kwargs: Dict[str, str] = {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0},
        gradient_kwargs: Dict[str, str] = {&#34;mu&#34;: None},
        num_iter: int = 30,
        save_freq: int = np.inf,
        verbose: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;XAI Explanation Generator

        Description:
            This class is the central module connecting all the library components with the purpose of generating an \
            explanation for a model&#39;s prediction. Those main components consist of the ``ExplanationModel``, \
            ``Optimizer``, ``GradientMethod`` and the ``InferenceWrapper``. \
            The ``Optimizer`` acts as sort of the engine of the explanation procedure, whereas the ``ExplanationModel``\
            poses as the loss function of an explanation method incorporated by the optimizer algorithm.
            After calling the ``run()`` method the optimizer starts producing a perturbed image (x_0) which \
            will get altered and optimized. \
            One can also specify the frequency of which savepoints are going to be created.

        Args:
            loss (Type[BaseExplanationModel], optional): Subclass of ``BaseExplanationModel`` - an explanation methods&#39; \
                loss function. Defaults to CEMLoss.
            optimizer (Type[BaseOptimizer], optional): Subclass of ``BaseOptimizer`` - the desired optimization \
                algorithm. Defaults to AdaExpGradOptimizer.
            gradient (Type[BaseGradient], optional): Subclass instance of ``BaseGradient`` - a particular gradient \
                method. Defaults to GradientEstimator.
            loss_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the loss function initilization.
                Defaults to { &#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 0, &#34;K&#34;: 50, &#34;AE&#34;: None, }.
            optimizer_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the optimizer initilization.
                Defaults to {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}.
            gradient_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the gradient method \
                initilization. Defaults to {&#34;mu&#34;: None}.
            num_iter (int, optional): Number of optimization iterations. Defaults to 30.
            save_freq (int, optional): Frequency of optimizer updates after which the object of optimization is saved. \
                The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf \
                (only result of last iteration is stored).
            verbose (bool, optional): Whether loss is printed. Defaults to False.
        &#34;&#34;&#34;
        self.loss, self.optimizer, self.gradient = loss, optimizer, gradient
        self._loss_kwargs, self._optimizer_kwargs, self._gradient_kwargs = (
            loss_kwargs,
            optimizer_kwargs,
            gradient_kwargs,
        )
        self.iter_count = 0
        self._num_iter = num_iter

        self.log_freq, self.save_freq = 1, min(save_freq, num_iter)

        self.logging_cb = logger._callback
        self.verbose = verbose

    def _init_components(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    ) -&gt; Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]:
        &#34;&#34;&#34;Initializes the components with the given image and inference function.

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. E.g. classification format as in [0.3, 0.2, 3.7].
        Returns:
            Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]: [description]
        &#34;&#34;&#34;
        # Loss function
        loss_instance: BaseExplanationModel = self.loss(
            inference=inference_call,
            org_img=image,
            **self._loss_kwargs,
        )

        # Gradient calculation
        gradient_instance: BaseGradient = self.gradient(
            loss=loss_instance,
            img_size=image.size,
            **self._gradient_kwargs,
        )

        # Optimization
        optimizer_instance: BaseOptimizer = self.optimizer(
            org_img=image,
            loss=loss_instance.get_loss,
            gradient=gradient_instance,
            num_iter=self._num_iter,
            x0=loss_instance._x0_generator(image),
            lower=loss_instance._lower,
            upper=loss_instance._upper,
            p_cb_epoch=self.save_freq,
            **self._optimizer_kwargs,
        )

        assert type(gradient_instance) in loss_instance.compatible_grad_methods, (
            &#34;Gradient method is not compatible with specified loss class. &#34;
            f&#34;{type(gradient_instance)} &lt;=&gt; {type(loss_instance)} \ņ&#34;
            f&#34;Gradient must be one of the following: {loss_instance.compatible_grad_methods}&#34;
        )

        return loss_instance, gradient_instance, optimizer_instance

    def _explain(self, optimizer: BaseOptimizer) -&gt; OrderedDict[str, np.ndarray]:
        &#34;&#34;&#34;Starts the explanation procedure. 
        
        Description:
            It will iterate over ``num_iter`` times and apply the \
            ``self.step()`` function which differs between different optimization algorithms. \
            Essentially, ``self.step()`` has to be implemented when adding a new optimization class. \
            The explanations are saved every ``save_freq``&#39;th iteration as savepoints in an OrderedDict.

        Args:
            optimizer (BaseOptimizer): Optimizer instance.

        Returns:
            OrderedDict[str, np.ndarray]: Holds the optimization result of every savepoint. \
                Dictionary keys represent the iteration count when the image was saved. Corresponding value consists \
                of the produced explanation of respective iteration.
        &#34;&#34;&#34;
        results = OrderedDict()

        while self.iter_count &lt;= self._num_iter:
            opt_result: OptimizeResult = optimizer.step()
            self.iter_count += 1

            #: Every ``save_freq``&#39;th iteration, object of the optimization is saved
            #: e.g. for CEM the perturbed image will be stored
            if general.check_epoch(self.iter_count, self.save_freq, self._num_iter):
                results[str(self.iter_count)] = opt_result.x.copy()

            #: Every ``log_freq``&#39;th iteration, the loss and l1 is logged on the terminal
            if self.verbose and general.check_epoch(self.iter_count, self.log_freq, self._num_iter):
                self.logging_cb(opt_result)

        return results

    def run(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
        meta_data: MetaData = None,
    ) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
        &#34;&#34;&#34;Method for starting the explanation procedure

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. The prediction result needs to be a 2D array.
            meta_data (MetaData, optional): Image meta data. Defaults to None.

        Returns:
            Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
                OrderedDict containing the explanations, meta data to the explained image.
        &#34;&#34;&#34;
        assert type(image) is np.ndarray and type(image) is not bool, &#34;Image is of unsupported type&#34;
        assert inference_call and type(inference_call) is not bool, &#34;Inference is of None Type&#34;

        try:
            loss, gradient, optimizer = self._init_components(image, inference_call)
            return self._explain(optimizer), meta_data
        except Exception as exc:
            print(f&#34;An exception occured: \n {exc}&#34;)
            traceback.print_exc()
            exit()

    def __copy__(self):
        return type(self)(
            self.loss,
            self.optimizer,
            self.gradient,
            self._loss_kwargs,
            self._optimizer_kwargs,
            self._gradient_kwargs,
            self._num_iter,
            self.save_freq,
            self.verbose,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="maxi.lib.explanation.explanation_generator.ExplanationGenerator"><code class="flex name class">
<span>class <span class="ident">ExplanationGenerator</span></span>
<span>(</span><span>loss: Type[<a title="maxi.lib.loss.base_explanation_model.BaseExplanationModel" href="../loss/base_explanation_model.html#maxi.lib.loss.base_explanation_model.BaseExplanationModel">BaseExplanationModel</a>] = maxi.lib.loss.cem_loss.CEMLoss, optimizer: Type[<a title="maxi.lib.computation_components.optimizer.base_optimizer.BaseOptimizer" href="../computation_components/optimizer/base_optimizer.html#maxi.lib.computation_components.optimizer.base_optimizer.BaseOptimizer">BaseOptimizer</a>] = maxi.lib.computation_components.optimizer.ada_exp_grad.AdaExpGradOptimizer, gradient: Type[<a title="maxi.lib.computation_components.gradient.base_gradient.BaseGradient" href="../computation_components/gradient/base_gradient.html#maxi.lib.computation_components.gradient.base_gradient.BaseGradient">BaseGradient</a>] = maxi.lib.computation_components.gradient.gradient_estimator.URVGradientEstimator, loss_kwargs: Dict[str, str] = {'mode': 'PP', 'c': 100, 'gamma': 0, 'K': 50, 'AE': None}, optimizer_kwargs: Dict[str, str] = {'l1': 0.5, 'l2': 0.5, 'eta': 1.0}, gradient_kwargs: Dict[str, str] = {'mu': None}, num_iter: int = 30, save_freq: int = inf, verbose: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>XAI Explanation Generator</p>
<h2 id="description">Description</h2>
<p>This class is the central module connecting all the library components with the purpose of generating an
explanation for a model's prediction. Those main components consist of the <code>ExplanationModel</code>,
<code>Optimizer</code>, <code>GradientMethod</code> and the <code>InferenceWrapper</code>.
The <code>Optimizer</code> acts as sort of the engine of the explanation procedure, whereas the <code>ExplanationModel</code>
poses as the loss function of an explanation method incorporated by the optimizer algorithm.
After calling the <code>run()</code> method the optimizer starts producing a perturbed image (x_0) which
will get altered and optimized.
One can also specify the frequency of which savepoints are going to be created.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>loss</code></strong> :&ensp;<code>Type[BaseExplanationModel]</code>, optional</dt>
<dd>Subclass of <code>BaseExplanationModel</code> - an explanation methods'
loss function. Defaults to CEMLoss.</dd>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>Type[BaseOptimizer]</code>, optional</dt>
<dd>Subclass of <code>BaseOptimizer</code> - the desired optimization
algorithm. Defaults to AdaExpGradOptimizer.</dd>
<dt><strong><code>gradient</code></strong> :&ensp;<code>Type[BaseGradient]</code>, optional</dt>
<dd>Subclass instance of <code>BaseGradient</code> - a particular gradient
method. Defaults to GradientEstimator.</dd>
<dt><strong><code>loss_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the loss function initilization.
Defaults to { "mode": "PP", "gamma": 0, "K": 50, "AE": None, }.</dd>
<dt><strong><code>optimizer_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the optimizer initilization.
Defaults to {"l1": 0.5, "l2": 0.5, "eta": 1.0}.</dd>
<dt><strong><code>gradient_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the gradient method
initilization. Defaults to {"mu": None}.</dd>
<dt><strong><code>num_iter</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of optimization iterations. Defaults to 30.</dd>
<dt><strong><code>save_freq</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Frequency of optimizer updates after which the object of optimization is saved.
The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf
(only result of last iteration is stored).</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether loss is printed. Defaults to False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExplanationGenerator:
    def __init__(
        self,
        loss: Type[BaseExplanationModel] = CEMLoss,
        optimizer: Type[BaseOptimizer] = AdaExpGradOptimizer,
        gradient: Type[BaseGradient] = URVGradientEstimator,
        loss_kwargs: Dict[str, str] = {
            &#34;mode&#34;: &#34;PP&#34;,
            &#34;c&#34;: 100,
            &#34;gamma&#34;: 0,
            &#34;K&#34;: 50,
            &#34;AE&#34;: None,
        },
        optimizer_kwargs: Dict[str, str] = {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0},
        gradient_kwargs: Dict[str, str] = {&#34;mu&#34;: None},
        num_iter: int = 30,
        save_freq: int = np.inf,
        verbose: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;XAI Explanation Generator

        Description:
            This class is the central module connecting all the library components with the purpose of generating an \
            explanation for a model&#39;s prediction. Those main components consist of the ``ExplanationModel``, \
            ``Optimizer``, ``GradientMethod`` and the ``InferenceWrapper``. \
            The ``Optimizer`` acts as sort of the engine of the explanation procedure, whereas the ``ExplanationModel``\
            poses as the loss function of an explanation method incorporated by the optimizer algorithm.
            After calling the ``run()`` method the optimizer starts producing a perturbed image (x_0) which \
            will get altered and optimized. \
            One can also specify the frequency of which savepoints are going to be created.

        Args:
            loss (Type[BaseExplanationModel], optional): Subclass of ``BaseExplanationModel`` - an explanation methods&#39; \
                loss function. Defaults to CEMLoss.
            optimizer (Type[BaseOptimizer], optional): Subclass of ``BaseOptimizer`` - the desired optimization \
                algorithm. Defaults to AdaExpGradOptimizer.
            gradient (Type[BaseGradient], optional): Subclass instance of ``BaseGradient`` - a particular gradient \
                method. Defaults to GradientEstimator.
            loss_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the loss function initilization.
                Defaults to { &#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 0, &#34;K&#34;: 50, &#34;AE&#34;: None, }.
            optimizer_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the optimizer initilization.
                Defaults to {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}.
            gradient_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the gradient method \
                initilization. Defaults to {&#34;mu&#34;: None}.
            num_iter (int, optional): Number of optimization iterations. Defaults to 30.
            save_freq (int, optional): Frequency of optimizer updates after which the object of optimization is saved. \
                The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf \
                (only result of last iteration is stored).
            verbose (bool, optional): Whether loss is printed. Defaults to False.
        &#34;&#34;&#34;
        self.loss, self.optimizer, self.gradient = loss, optimizer, gradient
        self._loss_kwargs, self._optimizer_kwargs, self._gradient_kwargs = (
            loss_kwargs,
            optimizer_kwargs,
            gradient_kwargs,
        )
        self.iter_count = 0
        self._num_iter = num_iter

        self.log_freq, self.save_freq = 1, min(save_freq, num_iter)

        self.logging_cb = logger._callback
        self.verbose = verbose

    def _init_components(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    ) -&gt; Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]:
        &#34;&#34;&#34;Initializes the components with the given image and inference function.

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. E.g. classification format as in [0.3, 0.2, 3.7].
        Returns:
            Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]: [description]
        &#34;&#34;&#34;
        # Loss function
        loss_instance: BaseExplanationModel = self.loss(
            inference=inference_call,
            org_img=image,
            **self._loss_kwargs,
        )

        # Gradient calculation
        gradient_instance: BaseGradient = self.gradient(
            loss=loss_instance,
            img_size=image.size,
            **self._gradient_kwargs,
        )

        # Optimization
        optimizer_instance: BaseOptimizer = self.optimizer(
            org_img=image,
            loss=loss_instance.get_loss,
            gradient=gradient_instance,
            num_iter=self._num_iter,
            x0=loss_instance._x0_generator(image),
            lower=loss_instance._lower,
            upper=loss_instance._upper,
            p_cb_epoch=self.save_freq,
            **self._optimizer_kwargs,
        )

        assert type(gradient_instance) in loss_instance.compatible_grad_methods, (
            &#34;Gradient method is not compatible with specified loss class. &#34;
            f&#34;{type(gradient_instance)} &lt;=&gt; {type(loss_instance)} \ņ&#34;
            f&#34;Gradient must be one of the following: {loss_instance.compatible_grad_methods}&#34;
        )

        return loss_instance, gradient_instance, optimizer_instance

    def _explain(self, optimizer: BaseOptimizer) -&gt; OrderedDict[str, np.ndarray]:
        &#34;&#34;&#34;Starts the explanation procedure. 
        
        Description:
            It will iterate over ``num_iter`` times and apply the \
            ``self.step()`` function which differs between different optimization algorithms. \
            Essentially, ``self.step()`` has to be implemented when adding a new optimization class. \
            The explanations are saved every ``save_freq``&#39;th iteration as savepoints in an OrderedDict.

        Args:
            optimizer (BaseOptimizer): Optimizer instance.

        Returns:
            OrderedDict[str, np.ndarray]: Holds the optimization result of every savepoint. \
                Dictionary keys represent the iteration count when the image was saved. Corresponding value consists \
                of the produced explanation of respective iteration.
        &#34;&#34;&#34;
        results = OrderedDict()

        while self.iter_count &lt;= self._num_iter:
            opt_result: OptimizeResult = optimizer.step()
            self.iter_count += 1

            #: Every ``save_freq``&#39;th iteration, object of the optimization is saved
            #: e.g. for CEM the perturbed image will be stored
            if general.check_epoch(self.iter_count, self.save_freq, self._num_iter):
                results[str(self.iter_count)] = opt_result.x.copy()

            #: Every ``log_freq``&#39;th iteration, the loss and l1 is logged on the terminal
            if self.verbose and general.check_epoch(self.iter_count, self.log_freq, self._num_iter):
                self.logging_cb(opt_result)

        return results

    def run(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
        meta_data: MetaData = None,
    ) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
        &#34;&#34;&#34;Method for starting the explanation procedure

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. The prediction result needs to be a 2D array.
            meta_data (MetaData, optional): Image meta data. Defaults to None.

        Returns:
            Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
                OrderedDict containing the explanations, meta data to the explained image.
        &#34;&#34;&#34;
        assert type(image) is np.ndarray and type(image) is not bool, &#34;Image is of unsupported type&#34;
        assert inference_call and type(inference_call) is not bool, &#34;Inference is of None Type&#34;

        try:
            loss, gradient, optimizer = self._init_components(image, inference_call)
            return self._explain(optimizer), meta_data
        except Exception as exc:
            print(f&#34;An exception occured: \n {exc}&#34;)
            traceback.print_exc()
            exit()

    def __copy__(self):
        return type(self)(
            self.loss,
            self.optimizer,
            self.gradient,
            self._loss_kwargs,
            self._optimizer_kwargs,
            self._gradient_kwargs,
            self._num_iter,
            self.save_freq,
            self.verbose,
        )</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="maxi.lib.explanation.explanation_generator.ExplanationGenerator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, image: numpy.ndarray, inference_call: Union[Callable[[numpy.ndarray], numpy.ndarray], <a title="maxi.lib.inference.inference_wrapper.InferenceWrapper" href="../inference/inference_wrapper.html#maxi.lib.inference.inference_wrapper.InferenceWrapper">InferenceWrapper</a>], meta_data: Dict[str, Any] = None) ‑> Tuple[OrderedDict[str, numpy.ndarray], Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Method for starting the explanation procedure</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be explained in [width, height, channels].</dd>
<dt><strong><code>inference_call</code></strong> :&ensp;<code>Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]</code></dt>
<dd>Inference method returning explanation model
compatible predictions. The prediction result needs to be a 2D array.</dd>
<dt><strong><code>meta_data</code></strong> :&ensp;<code>MetaData</code>, optional</dt>
<dd>Image meta data. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
OrderedDict containing the explanations, meta data to the explained image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(
    self,
    image: np.ndarray,
    inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    meta_data: MetaData = None,
) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
    &#34;&#34;&#34;Method for starting the explanation procedure

    Args:
        image (np.ndarray): Image to be explained in [width, height, channels].
        inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
            compatible predictions. The prediction result needs to be a 2D array.
        meta_data (MetaData, optional): Image meta data. Defaults to None.

    Returns:
        Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
            OrderedDict containing the explanations, meta data to the explained image.
    &#34;&#34;&#34;
    assert type(image) is np.ndarray and type(image) is not bool, &#34;Image is of unsupported type&#34;
    assert inference_call and type(inference_call) is not bool, &#34;Inference is of None Type&#34;

    try:
        loss, gradient, optimizer = self._init_components(image, inference_call)
        return self._explain(optimizer), meta_data
    except Exception as exc:
        print(f&#34;An exception occured: \n {exc}&#34;)
        traceback.print_exc()
        exit()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="maxi.lib.explanation" href="index.html">maxi.lib.explanation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="maxi.lib.explanation.explanation_generator.ExplanationGenerator" href="#maxi.lib.explanation.explanation_generator.ExplanationGenerator">ExplanationGenerator</a></code></h4>
<ul class="">
<li><code><a title="maxi.lib.explanation.explanation_generator.ExplanationGenerator.run" href="#maxi.lib.explanation.explanation_generator.ExplanationGenerator.run">run</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>