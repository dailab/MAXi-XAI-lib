<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>maxi.lib.explanation.explanation_generator API documentation</title>
<meta name="description" content="Explanation Generator" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js" integrity="sha512-rdhY3cbXURo13l/WU9VlaRyaIYeJ/KBakckXIvJNAQde8DgpOmE+eZf7ha4vdqVjTtwQt69bD2wH2LXob/LB7Q==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>maxi.lib.explanation.explanation_generator</code></h1>
</header>
<section id="section-intro">
<p>Explanation Generator</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Explanation Generator&#34;&#34;&#34;

__all__ = [&#34;ExplanationGenerator&#34;]

import traceback
from collections import OrderedDict
from typing import Callable, Type, Tuple, OrderedDict, Dict, Union

import numpy as np
from scipy.optimize import OptimizeResult

from ..computation_components.gradient.gradient_estimator import URVGradientEstimator
from ..computation_components.gradient.base_gradient import BaseGradient
from ..computation_components.optimizer.base_optimizer import BaseOptimizer
from ..computation_components.optimizer.ada_exp_grad import AdaExpGradOptimizer
from ..loss.base_explanation_model import BaseExplanationModel
from ..loss.cem_loss import CEMLoss
from ..inference.inference_wrapper import InferenceWrapper
from ..image_segmentation import BaseSegmentationHandler
from ...data.data_types import MetaData
from ...utils import logger, general


class ExplanationGenerator:
    def __init__(
        self,
        loss: Type[BaseExplanationModel] = CEMLoss,
        optimizer: Type[BaseOptimizer] = AdaExpGradOptimizer,
        gradient: Type[BaseGradient] = URVGradientEstimator,
        sg_algorithm: Type[BaseSegmentationHandler] = None,
        loss_kwargs: Dict[str, str] = None,
        optimizer_kwargs: Dict[str, str] = None,
        gradient_kwargs: Dict[str, str] = None,
        sg_kwargs: Dict[str, str] = None,
        num_iter: int = 30,
        save_freq: int = np.inf,
        verbose: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;XAI Explanation Generator

        Description:
            This class is the central module connecting all the library components with the purpose of generating an \
            explanation for a model&#39;s prediction. Those main components consist of the ``ExplanationModel``, \
            ``Optimizer``, ``GradientMethod`` and the ``InferenceWrapper``. \
            The ``Optimizer`` acts as sort of the engine of the explanation procedure, whereas the ``ExplanationModel``\
            poses as the loss function of an explanation method incorporated by the optimizer algorithm.
            After calling the ``run()`` method the optimizer starts producing a perturbed image (x_0) which \
            will get altered and optimized. \
            Optionally, the ``SegmentationHandler`` can be used to segment the image into regions of interest. \
            In order to use the ``SegmentationHandler`` the ``ExplanationModel`` has to be compatible with it. \
            See the ``SegmentationHandler`` documentation for more information. \
            One can also specify the frequency of which savepoints are going to be created.

        Args:
            loss (Type[BaseExplanationModel], optional): Subclass of ``BaseExplanationModel`` - an explanation methods&#39; \
                loss function. Defaults to CEMLoss.
            optimizer (Type[BaseOptimizer], optional): Subclass of ``BaseOptimizer`` - the desired optimization \
                algorithm. Defaults to AdaExpGradOptimizer.
            gradient (Type[BaseGradient], optional): Subclass instance of ``BaseGradient`` - a particular gradient \
                method. Defaults to GradientEstimator.
            sg_algorithm (Type[BaseSegmentationHandler], optional): Subclass of ``BaseSegmentationHandler`` - \
                chosen segmentation algorithm. Defaults to None.
            loss_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the loss function initilization.
                Defaults to { &#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 75, &#34;K&#34;: 10, &#34;AE&#34;: None}.
            optimizer_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the optimizer initilization.
                Defaults to {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}.
            gradient_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the gradient method \
                initilization. Defaults to {&#34;mu&#34;: None}.
            sg_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the segmentation algorithm. 
                Defaults to None. \
            num_iter (int, optional): Number of optimization iterations. Defaults to 30.
            save_freq (int, optional): Frequency of optimizer updates after which the object of optimization is saved. \
                The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf \
                (only result of last iteration is stored).
            verbose (bool, optional): Whether loss is printed. Defaults to False.
        &#34;&#34;&#34;
        if loss_kwargs is None:
            loss_kwargs = {&#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 75, &#34;K&#34;: 10, &#34;AE&#34;: None}
        if optimizer_kwargs is None:
            optimizer_kwargs = {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}
        if gradient_kwargs is None:
            gradient_kwargs = {&#34;mu&#34;: None}

        ExplanationGenerator._check_parsed_args(sg_algorithm, loss, optimizer, gradient)
        self.loss, self.optimizer, self.gradient = loss, optimizer, gradient
        self._loss_kwargs, self._optimizer_kwargs, self._gradient_kwargs = (
            loss_kwargs,
            optimizer_kwargs,
            gradient_kwargs,
        )
        self.iter_count = 0
        self._num_iter = num_iter

        self.log_freq, self.save_freq = 1, min(save_freq, num_iter)

        (
            self._superpixel_mode,
            self._sg_algorithm,
            self._sg_kwargs,
            self.superpixel_handler,
        ) = (&#34;superpixel&#34; in loss.__name__.lower(), sg_algorithm, sg_kwargs, None)

        if self._superpixel_mode and self._sg_kwargs is None:
            self._sg_kwargs = {}

        self.logging_cb = logger._callback
        self.verbose = verbose

    @staticmethod
    def _check_parsed_args(
        sg_algorithm: Type[BaseSegmentationHandler],
        loss: Type[BaseExplanationModel],
        optimizer: Type[BaseOptimizer],
        gradient: Type[BaseGradient],
    ) -&gt; None:
        if sg_algorithm and not issubclass(sg_algorithm, BaseSegmentationHandler):
            raise TypeError(
                &#34;Segmentation algorithm must be a subclass of BaseSegmentationHandler&#34;
            )
        if not issubclass(loss, BaseExplanationModel):
            raise TypeError(&#34;Loss must be a subclass of BaseExplanationModel&#34;)
        if not issubclass(optimizer, BaseOptimizer):
            raise TypeError(&#34;Optimizer must be a subclass of BaseOptimizer&#34;)
        if not issubclass(gradient, BaseGradient):
            raise TypeError(&#34;Gradient must be a subclass of BaseGradient&#34;)

    def _init_components(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    ) -&gt; Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]:
        &#34;&#34;&#34;Initializes the components with the given image and inference function.

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. E.g. classification format as in [0.3, 0.2, 3.7].
        Returns:
            Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]: Initialized components.
        &#34;&#34;&#34;

        # Segmentation mode
        if self._superpixel_mode:
            self.superpixel_handler = self._sg_algorithm(image=image, **self._sg_kwargs)

        # Loss function
        loss_instance: BaseExplanationModel = self.loss(
            inference=inference_call,
            org_img=image,
            superpixel_handler=self.superpixel_handler,
            **self._loss_kwargs,
        )

        # Gradient calculation
        gradient_instance: BaseGradient = self.gradient(
            loss=loss_instance,
            img_size=image.size,
            superpixel_mode=self._superpixel_mode,
            **self._gradient_kwargs,
        )

        if self._superpixel_mode:
            image = self.superpixel_handler.ones_weight_vector

        # Optimization
        optimizer_instance: BaseOptimizer = self.optimizer(
            org_img=image,
            loss=loss_instance.get_loss,
            gradient=gradient_instance,
            num_iter=self._num_iter,
            x0=loss_instance._x0_generator(image),
            lower=loss_instance._lower,
            upper=loss_instance._upper,
            p_cb_epoch=self.save_freq,
            **self._optimizer_kwargs,
        )

        assert type(gradient_instance) in loss_instance.compatible_grad_methods, (
            &#34;Gradient method is not compatible with specified loss class. &#34;
            f&#34;{type(gradient_instance)} &lt;=&gt; {type(loss_instance)} \ņ&#34;
            f&#34;Gradient must be one of the following: {loss_instance.compatible_grad_methods}&#34;
        )

        return loss_instance, gradient_instance, optimizer_instance

    def _explain(self, optimizer: BaseOptimizer) -&gt; OrderedDict[str, np.ndarray]:
        &#34;&#34;&#34;Starts the explanation procedure. 
        
        Description:
            It will iterate over ``num_iter`` times and apply the \
            ``self.step()`` function which differs between different optimization algorithms. \
            Essentially, ``self.step()`` has to be implemented when adding a new optimization class. \
            The explanations are saved every ``save_freq``&#39;th iteration as savepoints in an OrderedDict.

        Args:
            optimizer (BaseOptimizer): Optimizer instance.

        Returns:
            OrderedDict[str, np.ndarray]: Holds the optimization result of every savepoint. \
                Dictionary keys represent the iteration count when the image was saved. Corresponding value consists \
                of the produced explanation of respective iteration.
        &#34;&#34;&#34;
        results = OrderedDict()

        while self.iter_count &lt;= self._num_iter:
            opt_result: OptimizeResult = optimizer.step()
            self.iter_count += 1

            #: Every ``save_freq``&#39;th iteration, object of the optimization is saved
            #: e.g. for CEM the perturbed image will be stored
            if general.check_epoch(self.iter_count, self.save_freq, self._num_iter):
                res = opt_result.x.copy()
                results[str(self.iter_count)] = (
                    self.superpixel_handler.generate_img_from_weight_vector(res)
                    if self._superpixel_mode
                    else res
                )

            #: Every ``log_freq``&#39;th iteration, the loss and l1 is logged on the terminal
            if self.verbose and general.check_epoch(
                self.iter_count, self.log_freq, self._num_iter
            ):
                self.logging_cb(opt_result)

        return results

    def run(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
        meta_data: MetaData = None,
    ) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
        &#34;&#34;&#34;Method for starting the explanation procedure

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. The prediction result needs to be a 2D array.
            meta_data (MetaData, optional): Image meta data. Defaults to None.

        Returns:
            Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
                OrderedDict containing the explanations, meta data to the explained image.
        &#34;&#34;&#34;
        assert (
            type(image) is np.ndarray and type(image) is not bool
        ), &#34;Image is of unsupported type&#34;
        assert (
            inference_call and type(inference_call) is not bool
        ), &#34;Inference is of None Type&#34;

        # try:
        loss, gradient, optimizer = self._init_components(image, inference_call)
        return self._explain(optimizer), meta_data
        # except Exception as exc:
        #     print(f&#34;An exception occured: \n {exc}&#34;)
        #     traceback.print_exc()
        #     exit()

    def __copy__(self):
        raise NotImplementedError(
            &#34;Copy is not implemented. Asynchronous execution currently not supported.&#34;
        )
        return type(self)(
            self.loss,
            self.optimizer,
            self.gradient,
            self._loss_kwargs,
            self._optimizer_kwargs,
            self._gradient_kwargs,
            self._num_iter,
            self.save_freq,
            self.verbose,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="maxi.lib.explanation.explanation_generator.ExplanationGenerator"><code class="flex name class">
<span>class <span class="ident">ExplanationGenerator</span></span>
<span>(</span><span>loss: Type[<a title="maxi.lib.loss.base_explanation_model.BaseExplanationModel" href="../loss/base_explanation_model.html#maxi.lib.loss.base_explanation_model.BaseExplanationModel">BaseExplanationModel</a>] = maxi.lib.loss.cem_loss.CEMLoss, optimizer: Type[<a title="maxi.lib.computation_components.optimizer.base_optimizer.BaseOptimizer" href="../computation_components/optimizer/base_optimizer.html#maxi.lib.computation_components.optimizer.base_optimizer.BaseOptimizer">BaseOptimizer</a>] = maxi.lib.computation_components.optimizer.ada_exp_grad.AdaExpGradOptimizer, gradient: Type[<a title="maxi.lib.computation_components.gradient.base_gradient.BaseGradient" href="../computation_components/gradient/base_gradient.html#maxi.lib.computation_components.gradient.base_gradient.BaseGradient">BaseGradient</a>] = maxi.lib.computation_components.gradient.gradient_estimator.URVGradientEstimator, sg_algorithm: Type[<a title="maxi.lib.image_segmentation.base_seg_handler.BaseSegmentationHandler" href="../image_segmentation/base_seg_handler.html#maxi.lib.image_segmentation.base_seg_handler.BaseSegmentationHandler">BaseSegmentationHandler</a>] = None, loss_kwargs: Dict[str, str] = None, optimizer_kwargs: Dict[str, str] = None, gradient_kwargs: Dict[str, str] = None, sg_kwargs: Dict[str, str] = None, num_iter: int = 30, save_freq: int = inf, verbose: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>XAI Explanation Generator</p>
<h2 id="description">Description</h2>
<p>This class is the central module connecting all the library components with the purpose of generating an
explanation for a model's prediction. Those main components consist of the <code>ExplanationModel</code>,
<code>Optimizer</code>, <code>GradientMethod</code> and the <code>InferenceWrapper</code>.
The <code>Optimizer</code> acts as sort of the engine of the explanation procedure, whereas the <code>ExplanationModel</code>
poses as the loss function of an explanation method incorporated by the optimizer algorithm.
After calling the <code>run()</code> method the optimizer starts producing a perturbed image (x_0) which
will get altered and optimized.
Optionally, the <code>SegmentationHandler</code> can be used to segment the image into regions of interest.
In order to use the <code>SegmentationHandler</code> the <code>ExplanationModel</code> has to be compatible with it.
See the <code>SegmentationHandler</code> documentation for more information.
One can also specify the frequency of which savepoints are going to be created.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>loss</code></strong> :&ensp;<code>Type[BaseExplanationModel]</code>, optional</dt>
<dd>Subclass of <code>BaseExplanationModel</code> - an explanation methods'
loss function. Defaults to CEMLoss.</dd>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>Type[BaseOptimizer]</code>, optional</dt>
<dd>Subclass of <code>BaseOptimizer</code> - the desired optimization
algorithm. Defaults to AdaExpGradOptimizer.</dd>
<dt><strong><code>gradient</code></strong> :&ensp;<code>Type[BaseGradient]</code>, optional</dt>
<dd>Subclass instance of <code>BaseGradient</code> - a particular gradient
method. Defaults to GradientEstimator.</dd>
<dt><strong><code>sg_algorithm</code></strong> :&ensp;<code>Type[BaseSegmentationHandler]</code>, optional</dt>
<dd>Subclass of <code>BaseSegmentationHandler</code> -
chosen segmentation algorithm. Defaults to None.</dd>
<dt><strong><code>loss_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the loss function initilization.
Defaults to { "mode": "PP", "gamma": 75, "K": 10, "AE": None}.</dd>
<dt><strong><code>optimizer_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the optimizer initilization.
Defaults to {"l1": 0.5, "l2": 0.5, "eta": 1.0}.</dd>
<dt><strong><code>gradient_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the gradient method
initilization. Defaults to {"mu": None}.</dd>
<dt><strong><code>sg_kwargs</code></strong> :&ensp;<code>Dict[str, str]</code>, optional</dt>
<dd>Keyword arguments to be parsed to the segmentation algorithm.
Defaults to None.
num_iter (int, optional): Number of optimization iterations. Defaults to 30.</dd>
<dt><strong><code>save_freq</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Frequency of optimizer updates after which the object of optimization is saved.
The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf
(only result of last iteration is stored).</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether loss is printed. Defaults to False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExplanationGenerator:
    def __init__(
        self,
        loss: Type[BaseExplanationModel] = CEMLoss,
        optimizer: Type[BaseOptimizer] = AdaExpGradOptimizer,
        gradient: Type[BaseGradient] = URVGradientEstimator,
        sg_algorithm: Type[BaseSegmentationHandler] = None,
        loss_kwargs: Dict[str, str] = None,
        optimizer_kwargs: Dict[str, str] = None,
        gradient_kwargs: Dict[str, str] = None,
        sg_kwargs: Dict[str, str] = None,
        num_iter: int = 30,
        save_freq: int = np.inf,
        verbose: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;XAI Explanation Generator

        Description:
            This class is the central module connecting all the library components with the purpose of generating an \
            explanation for a model&#39;s prediction. Those main components consist of the ``ExplanationModel``, \
            ``Optimizer``, ``GradientMethod`` and the ``InferenceWrapper``. \
            The ``Optimizer`` acts as sort of the engine of the explanation procedure, whereas the ``ExplanationModel``\
            poses as the loss function of an explanation method incorporated by the optimizer algorithm.
            After calling the ``run()`` method the optimizer starts producing a perturbed image (x_0) which \
            will get altered and optimized. \
            Optionally, the ``SegmentationHandler`` can be used to segment the image into regions of interest. \
            In order to use the ``SegmentationHandler`` the ``ExplanationModel`` has to be compatible with it. \
            See the ``SegmentationHandler`` documentation for more information. \
            One can also specify the frequency of which savepoints are going to be created.

        Args:
            loss (Type[BaseExplanationModel], optional): Subclass of ``BaseExplanationModel`` - an explanation methods&#39; \
                loss function. Defaults to CEMLoss.
            optimizer (Type[BaseOptimizer], optional): Subclass of ``BaseOptimizer`` - the desired optimization \
                algorithm. Defaults to AdaExpGradOptimizer.
            gradient (Type[BaseGradient], optional): Subclass instance of ``BaseGradient`` - a particular gradient \
                method. Defaults to GradientEstimator.
            sg_algorithm (Type[BaseSegmentationHandler], optional): Subclass of ``BaseSegmentationHandler`` - \
                chosen segmentation algorithm. Defaults to None.
            loss_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the loss function initilization.
                Defaults to { &#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 75, &#34;K&#34;: 10, &#34;AE&#34;: None}.
            optimizer_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the optimizer initilization.
                Defaults to {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}.
            gradient_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the gradient method \
                initilization. Defaults to {&#34;mu&#34;: None}.
            sg_kwargs (Dict[str, str], optional): Keyword arguments to be parsed to the segmentation algorithm. 
                Defaults to None. \
            num_iter (int, optional): Number of optimization iterations. Defaults to 30.
            save_freq (int, optional): Frequency of optimizer updates after which the object of optimization is saved. \
                The savepoints will be stored in an OrderedDict and eventually returned. Defaults to np.inf \
                (only result of last iteration is stored).
            verbose (bool, optional): Whether loss is printed. Defaults to False.
        &#34;&#34;&#34;
        if loss_kwargs is None:
            loss_kwargs = {&#34;mode&#34;: &#34;PP&#34;, &#34;gamma&#34;: 75, &#34;K&#34;: 10, &#34;AE&#34;: None}
        if optimizer_kwargs is None:
            optimizer_kwargs = {&#34;l1&#34;: 0.5, &#34;l2&#34;: 0.5, &#34;eta&#34;: 1.0}
        if gradient_kwargs is None:
            gradient_kwargs = {&#34;mu&#34;: None}

        ExplanationGenerator._check_parsed_args(sg_algorithm, loss, optimizer, gradient)
        self.loss, self.optimizer, self.gradient = loss, optimizer, gradient
        self._loss_kwargs, self._optimizer_kwargs, self._gradient_kwargs = (
            loss_kwargs,
            optimizer_kwargs,
            gradient_kwargs,
        )
        self.iter_count = 0
        self._num_iter = num_iter

        self.log_freq, self.save_freq = 1, min(save_freq, num_iter)

        (
            self._superpixel_mode,
            self._sg_algorithm,
            self._sg_kwargs,
            self.superpixel_handler,
        ) = (&#34;superpixel&#34; in loss.__name__.lower(), sg_algorithm, sg_kwargs, None)

        if self._superpixel_mode and self._sg_kwargs is None:
            self._sg_kwargs = {}

        self.logging_cb = logger._callback
        self.verbose = verbose

    @staticmethod
    def _check_parsed_args(
        sg_algorithm: Type[BaseSegmentationHandler],
        loss: Type[BaseExplanationModel],
        optimizer: Type[BaseOptimizer],
        gradient: Type[BaseGradient],
    ) -&gt; None:
        if sg_algorithm and not issubclass(sg_algorithm, BaseSegmentationHandler):
            raise TypeError(
                &#34;Segmentation algorithm must be a subclass of BaseSegmentationHandler&#34;
            )
        if not issubclass(loss, BaseExplanationModel):
            raise TypeError(&#34;Loss must be a subclass of BaseExplanationModel&#34;)
        if not issubclass(optimizer, BaseOptimizer):
            raise TypeError(&#34;Optimizer must be a subclass of BaseOptimizer&#34;)
        if not issubclass(gradient, BaseGradient):
            raise TypeError(&#34;Gradient must be a subclass of BaseGradient&#34;)

    def _init_components(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    ) -&gt; Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]:
        &#34;&#34;&#34;Initializes the components with the given image and inference function.

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. E.g. classification format as in [0.3, 0.2, 3.7].
        Returns:
            Tuple[BaseExplanationModel, BaseGradient, BaseOptimizer]: Initialized components.
        &#34;&#34;&#34;

        # Segmentation mode
        if self._superpixel_mode:
            self.superpixel_handler = self._sg_algorithm(image=image, **self._sg_kwargs)

        # Loss function
        loss_instance: BaseExplanationModel = self.loss(
            inference=inference_call,
            org_img=image,
            superpixel_handler=self.superpixel_handler,
            **self._loss_kwargs,
        )

        # Gradient calculation
        gradient_instance: BaseGradient = self.gradient(
            loss=loss_instance,
            img_size=image.size,
            superpixel_mode=self._superpixel_mode,
            **self._gradient_kwargs,
        )

        if self._superpixel_mode:
            image = self.superpixel_handler.ones_weight_vector

        # Optimization
        optimizer_instance: BaseOptimizer = self.optimizer(
            org_img=image,
            loss=loss_instance.get_loss,
            gradient=gradient_instance,
            num_iter=self._num_iter,
            x0=loss_instance._x0_generator(image),
            lower=loss_instance._lower,
            upper=loss_instance._upper,
            p_cb_epoch=self.save_freq,
            **self._optimizer_kwargs,
        )

        assert type(gradient_instance) in loss_instance.compatible_grad_methods, (
            &#34;Gradient method is not compatible with specified loss class. &#34;
            f&#34;{type(gradient_instance)} &lt;=&gt; {type(loss_instance)} \ņ&#34;
            f&#34;Gradient must be one of the following: {loss_instance.compatible_grad_methods}&#34;
        )

        return loss_instance, gradient_instance, optimizer_instance

    def _explain(self, optimizer: BaseOptimizer) -&gt; OrderedDict[str, np.ndarray]:
        &#34;&#34;&#34;Starts the explanation procedure. 
        
        Description:
            It will iterate over ``num_iter`` times and apply the \
            ``self.step()`` function which differs between different optimization algorithms. \
            Essentially, ``self.step()`` has to be implemented when adding a new optimization class. \
            The explanations are saved every ``save_freq``&#39;th iteration as savepoints in an OrderedDict.

        Args:
            optimizer (BaseOptimizer): Optimizer instance.

        Returns:
            OrderedDict[str, np.ndarray]: Holds the optimization result of every savepoint. \
                Dictionary keys represent the iteration count when the image was saved. Corresponding value consists \
                of the produced explanation of respective iteration.
        &#34;&#34;&#34;
        results = OrderedDict()

        while self.iter_count &lt;= self._num_iter:
            opt_result: OptimizeResult = optimizer.step()
            self.iter_count += 1

            #: Every ``save_freq``&#39;th iteration, object of the optimization is saved
            #: e.g. for CEM the perturbed image will be stored
            if general.check_epoch(self.iter_count, self.save_freq, self._num_iter):
                res = opt_result.x.copy()
                results[str(self.iter_count)] = (
                    self.superpixel_handler.generate_img_from_weight_vector(res)
                    if self._superpixel_mode
                    else res
                )

            #: Every ``log_freq``&#39;th iteration, the loss and l1 is logged on the terminal
            if self.verbose and general.check_epoch(
                self.iter_count, self.log_freq, self._num_iter
            ):
                self.logging_cb(opt_result)

        return results

    def run(
        self,
        image: np.ndarray,
        inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
        meta_data: MetaData = None,
    ) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
        &#34;&#34;&#34;Method for starting the explanation procedure

        Args:
            image (np.ndarray): Image to be explained in [width, height, channels].
            inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
                compatible predictions. The prediction result needs to be a 2D array.
            meta_data (MetaData, optional): Image meta data. Defaults to None.

        Returns:
            Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
                OrderedDict containing the explanations, meta data to the explained image.
        &#34;&#34;&#34;
        assert (
            type(image) is np.ndarray and type(image) is not bool
        ), &#34;Image is of unsupported type&#34;
        assert (
            inference_call and type(inference_call) is not bool
        ), &#34;Inference is of None Type&#34;

        # try:
        loss, gradient, optimizer = self._init_components(image, inference_call)
        return self._explain(optimizer), meta_data
        # except Exception as exc:
        #     print(f&#34;An exception occured: \n {exc}&#34;)
        #     traceback.print_exc()
        #     exit()

    def __copy__(self):
        raise NotImplementedError(
            &#34;Copy is not implemented. Asynchronous execution currently not supported.&#34;
        )
        return type(self)(
            self.loss,
            self.optimizer,
            self.gradient,
            self._loss_kwargs,
            self._optimizer_kwargs,
            self._gradient_kwargs,
            self._num_iter,
            self.save_freq,
            self.verbose,
        )</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="maxi.lib.explanation.explanation_generator.ExplanationGenerator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, image: numpy.ndarray, inference_call: Union[Callable[[numpy.ndarray], numpy.ndarray], <a title="maxi.lib.inference.inference_wrapper.InferenceWrapper" href="../inference/inference_wrapper.html#maxi.lib.inference.inference_wrapper.InferenceWrapper">InferenceWrapper</a>], meta_data: Dict[str, Any] = None) ‑> Tuple[OrderedDict[str, numpy.ndarray], Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Method for starting the explanation procedure</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be explained in [width, height, channels].</dd>
<dt><strong><code>inference_call</code></strong> :&ensp;<code>Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]</code></dt>
<dd>Inference method returning explanation model
compatible predictions. The prediction result needs to be a 2D array.</dd>
<dt><strong><code>meta_data</code></strong> :&ensp;<code>MetaData</code>, optional</dt>
<dd>Image meta data. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
OrderedDict containing the explanations, meta data to the explained image.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(
    self,
    image: np.ndarray,
    inference_call: Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper],
    meta_data: MetaData = None,
) -&gt; Tuple[OrderedDict[str, np.ndarray], MetaData]:
    &#34;&#34;&#34;Method for starting the explanation procedure

    Args:
        image (np.ndarray): Image to be explained in [width, height, channels].
        inference_call (Union[Callable[[np.ndarray], np.ndarray], InferenceWrapper]): Inference method returning explanation model \
            compatible predictions. The prediction result needs to be a 2D array.
        meta_data (MetaData, optional): Image meta data. Defaults to None.

    Returns:
        Tuple[OrderedDict[str, np.ndarray], OrderedDict[str, np.ndarray], MetaData]:
            OrderedDict containing the explanations, meta data to the explained image.
    &#34;&#34;&#34;
    assert (
        type(image) is np.ndarray and type(image) is not bool
    ), &#34;Image is of unsupported type&#34;
    assert (
        inference_call and type(inference_call) is not bool
    ), &#34;Inference is of None Type&#34;

    # try:
    loss, gradient, optimizer = self._init_components(image, inference_call)
    return self._explain(optimizer), meta_data
    # except Exception as exc:
    #     print(f&#34;An exception occured: \n {exc}&#34;)
    #     traceback.print_exc()
    #     exit()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="maxi.lib.explanation" href="index.html">maxi.lib.explanation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="maxi.lib.explanation.explanation_generator.ExplanationGenerator" href="#maxi.lib.explanation.explanation_generator.ExplanationGenerator">ExplanationGenerator</a></code></h4>
<ul class="">
<li><code><a title="maxi.lib.explanation.explanation_generator.ExplanationGenerator.run" href="#maxi.lib.explanation.explanation_generator.ExplanationGenerator.run">run</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>