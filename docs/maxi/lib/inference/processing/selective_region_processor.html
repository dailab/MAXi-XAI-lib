<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>maxi.lib.inference.processing.selective_region_processor API documentation</title>
<meta name="description" content="Selective Region Processor" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.10.0/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.10.0/highlight.min.js" integrity="sha512-6yoqbrcLAHDWAdQmiRlHG4+m0g/CT/V9AGyxabG8j7Jk8j3r3K6due7oqpiRMZqcYe9WM2gPcaNNxnl2ux+3tA==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>maxi.lib.inference.processing.selective_region_processor</code></h1>
</header>
<section id="section-intro">
<p>Selective Region Processor</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Selective Region Processor&#34;&#34;&#34;
import numpy as np
import torch

from ....data.data_types import EntityRect


class SelectiveRegionProcessor:
    def __init__(self, orig_image: np.ndarray, entity_region: EntityRect) -&gt; None:
        &#34;&#34;&#34;Selective Region Processor

        Description:
            Holds a copy of the original image in order to perform inference on \
            model conforming format. The preprocessing procedure includes replacing \
            the region to be altered with the parsed one. The prediction result for the selected \
            region is afterwards extracted in the postprocessing method.
            Thus, this class must hold the coordinates of the region containing the object \
            for explanation.

        Args:
            orig_image (np.ndarray): The original full-sized image.
            entity_region (EntityRect): Coordinates of the image region to be perturbed.
        &#34;&#34;&#34;
        self.orig_img = orig_image
        self._target = entity_region
        self.check_sizes()

    def check_sizes(self):
        assert (
            self.orig_img.shape[0] &gt;= self.target[&#34;w&#34;] and self.orig_img.shape[1] &gt;= self.target[&#34;h&#34;]
        ), &#34;Target region has a dimension which is larger than of the original image&#34;

    @property
    def target(self) -&gt; None:
        return self._target

    @target.setter
    def target(self, new_target_region: EntityRect) -&gt; None:
        self._target = new_target_region

    def preprocess(self, new_region: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

        Description:
            Makes a copy of the original image, replaces the target region with \
            the parsed one in &#39;new_region&#39; and returns the resulting image.

        Args:
            new_region (np.ndarray): The new region to be infered. Shape in [bs, self.w, self.h, c].

        Returns:
            np.ndarray: Batch of full-sized images with &#39;new_region&#39; at [self.x, self.y] (upper-left).
        &#34;&#34;&#34;
        if new_region.ndim &lt; 4:
            return self.nonbatched_replacement(new_region)
        else:
            return self.batched_replacement(new_region)

    def batched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
        assert (
            new_region.shape[1] == self.target[&#34;w&#34;] and new_region.shape[2] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = np.stack([self.orig_img.copy() for _ in range(new_region.shape[0])], axis=0)
        tmp_image[
            :,
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image

    def nonbatched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
        assert (
            new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = self.orig_img.copy()
        tmp_image[
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image

    def postprocess(self, segmentation_mask: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Extracts the region of the segmentation mask corresponding to the target region.

        Args:^
            segmentation_mask (np.ndarray): The prediction mask, has to be of the same shape as ``self.orig_img``.

        Returns:
            np.ndarray: Segmentation mask of the target region. Shape in [self.w, self.h].
        &#34;&#34;&#34;
        assert (
            segmentation_mask.shape[1:] == self.orig_img.shape[:2]
        ), &#34;Segmentation mask must be of the same shape as the original image&#34;
        return segmentation_mask[
            :,
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ]


class Torch_SelectiveRegionProcessor(SelectiveRegionProcessor):
    def __init__(self, orig_image: np.ndarray, entity_region: EntityRect) -&gt; None:
        &#34;&#34;&#34;Selective Region Processor

        Description:
            Holds a copy of the original image in order to perform inference on \
            model conforming format. The preprocessing procedure includes replacing \
            the region to be altered with the parsed one. The prediction result for the selected \
            region is afterwards extracted in the postprocessing method.
            Thus, this class must hold the coordinates of the region containing the object \
            for explanation.

        Args:
            orig_image (np.ndarray): The original full-sized image.
            entity_region (EntityRect): Coordinates of the image region to be perturbed.
        &#34;&#34;&#34;
        import torch

        self.orig_img = orig_image
        self.torch_orig_img = torch.tensor(orig_image, dtype=torch.float32, requires_grad=True)
        self._target = entity_region
        self.check_sizes()

    def preprocess(self, new_region: torch.Tensor) -&gt; torch.Tensor:
        &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

        Description:
            Makes a copy of the original image, replaces the target region with \
            the parsed one in &#39;new_region&#39; and returns the resulting image.

        Args:
            new_region (np.ndarray): The new region to be infered. Shape in [self.w, self.h, c].

        Returns:
            np.ndarray: Full-sized image with &#39;new_region&#39; at [self.x, self.y] (upper-left).
        &#34;&#34;&#34;
        assert (
            new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = (
            torch.autograd.Variable(self.torch_orig_img.clone(), requires_grad=True)
            if type(new_region) is torch.Tensor
            else self.orig_img.copy()
        )
        tmp_image[
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor"><code class="flex name class">
<span>class <span class="ident">SelectiveRegionProcessor</span></span>
<span>(</span><span>orig_image: numpy.ndarray, entity_region: <a title="maxi.data.data_types.EntityRect" href="../../../data/data_types.html#maxi.data.data_types.EntityRect">EntityRect</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Selective Region Processor</p>
<h2 id="description">Description</h2>
<p>Holds a copy of the original image in order to perform inference on
model conforming format. The preprocessing procedure includes replacing
the region to be altered with the parsed one. The prediction result for the selected
region is afterwards extracted in the postprocessing method.
Thus, this class must hold the coordinates of the region containing the object
for explanation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orig_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The original full-sized image.</dd>
<dt><strong><code>entity_region</code></strong> :&ensp;<code>EntityRect</code></dt>
<dd>Coordinates of the image region to be perturbed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SelectiveRegionProcessor:
    def __init__(self, orig_image: np.ndarray, entity_region: EntityRect) -&gt; None:
        &#34;&#34;&#34;Selective Region Processor

        Description:
            Holds a copy of the original image in order to perform inference on \
            model conforming format. The preprocessing procedure includes replacing \
            the region to be altered with the parsed one. The prediction result for the selected \
            region is afterwards extracted in the postprocessing method.
            Thus, this class must hold the coordinates of the region containing the object \
            for explanation.

        Args:
            orig_image (np.ndarray): The original full-sized image.
            entity_region (EntityRect): Coordinates of the image region to be perturbed.
        &#34;&#34;&#34;
        self.orig_img = orig_image
        self._target = entity_region
        self.check_sizes()

    def check_sizes(self):
        assert (
            self.orig_img.shape[0] &gt;= self.target[&#34;w&#34;] and self.orig_img.shape[1] &gt;= self.target[&#34;h&#34;]
        ), &#34;Target region has a dimension which is larger than of the original image&#34;

    @property
    def target(self) -&gt; None:
        return self._target

    @target.setter
    def target(self, new_target_region: EntityRect) -&gt; None:
        self._target = new_target_region

    def preprocess(self, new_region: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

        Description:
            Makes a copy of the original image, replaces the target region with \
            the parsed one in &#39;new_region&#39; and returns the resulting image.

        Args:
            new_region (np.ndarray): The new region to be infered. Shape in [bs, self.w, self.h, c].

        Returns:
            np.ndarray: Batch of full-sized images with &#39;new_region&#39; at [self.x, self.y] (upper-left).
        &#34;&#34;&#34;
        if new_region.ndim &lt; 4:
            return self.nonbatched_replacement(new_region)
        else:
            return self.batched_replacement(new_region)

    def batched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
        assert (
            new_region.shape[1] == self.target[&#34;w&#34;] and new_region.shape[2] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = np.stack([self.orig_img.copy() for _ in range(new_region.shape[0])], axis=0)
        tmp_image[
            :,
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image

    def nonbatched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
        assert (
            new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = self.orig_img.copy()
        tmp_image[
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image

    def postprocess(self, segmentation_mask: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Extracts the region of the segmentation mask corresponding to the target region.

        Args:^
            segmentation_mask (np.ndarray): The prediction mask, has to be of the same shape as ``self.orig_img``.

        Returns:
            np.ndarray: Segmentation mask of the target region. Shape in [self.w, self.h].
        &#34;&#34;&#34;
        assert (
            segmentation_mask.shape[1:] == self.orig_img.shape[:2]
        ), &#34;Segmentation mask must be of the same shape as the original image&#34;
        return segmentation_mask[
            :,
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ]</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor" href="#maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor">Torch_SelectiveRegionProcessor</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.target"><code class="name">var <span class="ident">target</span> : None</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def target(self) -&gt; None:
    return self._target</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.batched_replacement"><code class="name flex">
<span>def <span class="ident">batched_replacement</span></span>(<span>self, new_region: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def batched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
    assert (
        new_region.shape[1] == self.target[&#34;w&#34;] and new_region.shape[2] == self.target[&#34;h&#34;]
    ), &#34;Parsed region is of different size compared to the target region&#34;

    tmp_image = np.stack([self.orig_img.copy() for _ in range(new_region.shape[0])], axis=0)
    tmp_image[
        :,
        self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
        self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
    ] = new_region
    return tmp_image</code></pre>
</details>
</dd>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.check_sizes"><code class="name flex">
<span>def <span class="ident">check_sizes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_sizes(self):
    assert (
        self.orig_img.shape[0] &gt;= self.target[&#34;w&#34;] and self.orig_img.shape[1] &gt;= self.target[&#34;h&#34;]
    ), &#34;Target region has a dimension which is larger than of the original image&#34;</code></pre>
</details>
</dd>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.nonbatched_replacement"><code class="name flex">
<span>def <span class="ident">nonbatched_replacement</span></span>(<span>self, new_region: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nonbatched_replacement(self, new_region: np.ndarray) -&gt; np.ndarray:
    assert (
        new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
    ), &#34;Parsed region is of different size compared to the target region&#34;

    tmp_image = self.orig_img.copy()
    tmp_image[
        self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
        self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
    ] = new_region
    return tmp_image</code></pre>
</details>
</dd>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.postprocess"><code class="name flex">
<span>def <span class="ident">postprocess</span></span>(<span>self, segmentation_mask: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts the region of the segmentation mask corresponding to the target region.</p>
<p>Args:^
segmentation_mask (np.ndarray): The prediction mask, has to be of the same shape as <code>self.orig_img</code>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Segmentation mask of the target region. Shape in [self.w, self.h].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def postprocess(self, segmentation_mask: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Extracts the region of the segmentation mask corresponding to the target region.

    Args:^
        segmentation_mask (np.ndarray): The prediction mask, has to be of the same shape as ``self.orig_img``.

    Returns:
        np.ndarray: Segmentation mask of the target region. Shape in [self.w, self.h].
    &#34;&#34;&#34;
    assert (
        segmentation_mask.shape[1:] == self.orig_img.shape[:2]
    ), &#34;Segmentation mask must be of the same shape as the original image&#34;
    return segmentation_mask[
        :,
        self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
        self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
    ]</code></pre>
</details>
</dd>
<dt id="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.preprocess"><code class="name flex">
<span>def <span class="ident">preprocess</span></span>(<span>self, new_region: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Replaces the target region in the original image with the parsed one before inference.</p>
<h2 id="description">Description</h2>
<p>Makes a copy of the original image, replaces the target region with
the parsed one in 'new_region' and returns the resulting image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>new_region</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The new region to be infered. Shape in [bs, self.w, self.h, c].</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Batch of full-sized images with 'new_region' at [self.x, self.y] (upper-left).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess(self, new_region: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

    Description:
        Makes a copy of the original image, replaces the target region with \
        the parsed one in &#39;new_region&#39; and returns the resulting image.

    Args:
        new_region (np.ndarray): The new region to be infered. Shape in [bs, self.w, self.h, c].

    Returns:
        np.ndarray: Batch of full-sized images with &#39;new_region&#39; at [self.x, self.y] (upper-left).
    &#34;&#34;&#34;
    if new_region.ndim &lt; 4:
        return self.nonbatched_replacement(new_region)
    else:
        return self.batched_replacement(new_region)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor"><code class="flex name class">
<span>class <span class="ident">Torch_SelectiveRegionProcessor</span></span>
<span>(</span><span>orig_image: numpy.ndarray, entity_region: <a title="maxi.data.data_types.EntityRect" href="../../../data/data_types.html#maxi.data.data_types.EntityRect">EntityRect</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Selective Region Processor</p>
<h2 id="description">Description</h2>
<p>Holds a copy of the original image in order to perform inference on
model conforming format. The preprocessing procedure includes replacing
the region to be altered with the parsed one. The prediction result for the selected
region is afterwards extracted in the postprocessing method.
Thus, this class must hold the coordinates of the region containing the object
for explanation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orig_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The original full-sized image.</dd>
<dt><strong><code>entity_region</code></strong> :&ensp;<code>EntityRect</code></dt>
<dd>Coordinates of the image region to be perturbed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Torch_SelectiveRegionProcessor(SelectiveRegionProcessor):
    def __init__(self, orig_image: np.ndarray, entity_region: EntityRect) -&gt; None:
        &#34;&#34;&#34;Selective Region Processor

        Description:
            Holds a copy of the original image in order to perform inference on \
            model conforming format. The preprocessing procedure includes replacing \
            the region to be altered with the parsed one. The prediction result for the selected \
            region is afterwards extracted in the postprocessing method.
            Thus, this class must hold the coordinates of the region containing the object \
            for explanation.

        Args:
            orig_image (np.ndarray): The original full-sized image.
            entity_region (EntityRect): Coordinates of the image region to be perturbed.
        &#34;&#34;&#34;
        import torch

        self.orig_img = orig_image
        self.torch_orig_img = torch.tensor(orig_image, dtype=torch.float32, requires_grad=True)
        self._target = entity_region
        self.check_sizes()

    def preprocess(self, new_region: torch.Tensor) -&gt; torch.Tensor:
        &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

        Description:
            Makes a copy of the original image, replaces the target region with \
            the parsed one in &#39;new_region&#39; and returns the resulting image.

        Args:
            new_region (np.ndarray): The new region to be infered. Shape in [self.w, self.h, c].

        Returns:
            np.ndarray: Full-sized image with &#39;new_region&#39; at [self.x, self.y] (upper-left).
        &#34;&#34;&#34;
        assert (
            new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
        ), &#34;Parsed region is of different size compared to the target region&#34;

        tmp_image = (
            torch.autograd.Variable(self.torch_orig_img.clone(), requires_grad=True)
            if type(new_region) is torch.Tensor
            else self.orig_img.copy()
        )
        tmp_image[
            self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
            self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
        ] = new_region
        return tmp_image</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor">SelectiveRegionProcessor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor.preprocess"><code class="name flex">
<span>def <span class="ident">preprocess</span></span>(<span>self, new_region: torch.Tensor) ‑> torch.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Replaces the target region in the original image with the parsed one before inference.</p>
<h2 id="description">Description</h2>
<p>Makes a copy of the original image, replaces the target region with
the parsed one in 'new_region' and returns the resulting image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>new_region</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The new region to be infered. Shape in [self.w, self.h, c].</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Full-sized image with 'new_region' at [self.x, self.y] (upper-left).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess(self, new_region: torch.Tensor) -&gt; torch.Tensor:
    &#34;&#34;&#34;Replaces the target region in the original image with the parsed one before inference.

    Description:
        Makes a copy of the original image, replaces the target region with \
        the parsed one in &#39;new_region&#39; and returns the resulting image.

    Args:
        new_region (np.ndarray): The new region to be infered. Shape in [self.w, self.h, c].

    Returns:
        np.ndarray: Full-sized image with &#39;new_region&#39; at [self.x, self.y] (upper-left).
    &#34;&#34;&#34;
    assert (
        new_region.shape[0] == self.target[&#34;w&#34;] and new_region.shape[1] == self.target[&#34;h&#34;]
    ), &#34;Parsed region is of different size compared to the target region&#34;

    tmp_image = (
        torch.autograd.Variable(self.torch_orig_img.clone(), requires_grad=True)
        if type(new_region) is torch.Tensor
        else self.orig_img.copy()
    )
    tmp_image[
        self.target[&#34;x&#34;] : self.target[&#34;x&#34;] + self.target[&#34;w&#34;],
        self.target[&#34;y&#34;] : self.target[&#34;y&#34;] + self.target[&#34;h&#34;],
    ] = new_region
    return tmp_image</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor">SelectiveRegionProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.postprocess" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.postprocess">postprocess</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="maxi.lib.inference.processing" href="index.html">maxi.lib.inference.processing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor">SelectiveRegionProcessor</a></code></h4>
<ul class="">
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.batched_replacement" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.batched_replacement">batched_replacement</a></code></li>
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.check_sizes" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.check_sizes">check_sizes</a></code></li>
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.nonbatched_replacement" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.nonbatched_replacement">nonbatched_replacement</a></code></li>
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.postprocess" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.postprocess">postprocess</a></code></li>
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.preprocess" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.preprocess">preprocess</a></code></li>
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.target" href="#maxi.lib.inference.processing.selective_region_processor.SelectiveRegionProcessor.target">target</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor" href="#maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor">Torch_SelectiveRegionProcessor</a></code></h4>
<ul class="">
<li><code><a title="maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor.preprocess" href="#maxi.lib.inference.processing.selective_region_processor.Torch_SelectiveRegionProcessor.preprocess">preprocess</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>